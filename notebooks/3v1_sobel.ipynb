{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leer las imágenes\n",
    "\n",
    "ruta_carpeta = '/data_lids/home/walter/Lab/alignment/basep/processed/rotations_064'\n",
    "nombres_imagenes = [f for f in os.listdir(ruta_carpeta) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nombres_imagenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []\n",
    "\n",
    "for nombre_imagen in nombres_imagenes:\n",
    "    ruta_imagen = os.path.join(ruta_carpeta, nombre_imagen)\n",
    "    imagen = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)  # Leer en escala de grises\n",
    "    \n",
    "    # 2. Aplicar el filtro de Sobel\n",
    "    sobelx = cv2.Sobel(imagen, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(imagen, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    magnitud_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    # Aplanar la imagen\n",
    "    imagen_aplanada = magnitud_sobel.flatten()\n",
    "    \n",
    "    # 3. Extraer el ángulo del nombre de la imagen\n",
    "    angulo = int(nombre_imagen.split('_r')[-1].split('.png')[0])\n",
    "    \n",
    "    # Agregar al conjunto de datos\n",
    "    datos.append(np.append(imagen_aplanada, angulo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Crear el DataFrame\n",
    "columnas = [f'pixel_{i}' for i in range(64*64)] + ['Angulo']\n",
    "df = pd.DataFrame(datos, columns=columnas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_4087</th>\n",
       "      <th>pixel_4088</th>\n",
       "      <th>pixel_4089</th>\n",
       "      <th>pixel_4090</th>\n",
       "      <th>pixel_4091</th>\n",
       "      <th>pixel_4092</th>\n",
       "      <th>pixel_4093</th>\n",
       "      <th>pixel_4094</th>\n",
       "      <th>pixel_4095</th>\n",
       "      <th>Angulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>...</td>\n",
       "      <td>196.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>262.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>216.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0      0.0    172.0    452.0    362.0     36.0    190.0    134.0      2.0   \n",
       "1      0.0    214.0     92.0    354.0    310.0     86.0     70.0    164.0   \n",
       "2      0.0    134.0     36.0    180.0     94.0    166.0    396.0    362.0   \n",
       "3      0.0    164.0    238.0    420.0    244.0    300.0    170.0    496.0   \n",
       "4      0.0    190.0    248.0    192.0    158.0    170.0     82.0    222.0   \n",
       "\n",
       "   pixel_8  pixel_9  ...  pixel_4087  pixel_4088  pixel_4089  pixel_4090  \\\n",
       "0    150.0    232.0  ...       196.0       106.0       150.0       200.0   \n",
       "1    124.0     44.0  ...       402.0        40.0       280.0       290.0   \n",
       "2     84.0     96.0  ...       262.0       168.0       584.0       438.0   \n",
       "3    296.0     44.0  ...       166.0       242.0       494.0        44.0   \n",
       "4    462.0    316.0  ...       216.0       128.0       376.0       490.0   \n",
       "\n",
       "   pixel_4091  pixel_4092  pixel_4093  pixel_4094  pixel_4095  Angulo  \n",
       "0       180.0        98.0       536.0       748.0         0.0     0.0  \n",
       "1       154.0        40.0       200.0       106.0         0.0    30.0  \n",
       "2        58.0       236.0       388.0       214.0         0.0    30.0  \n",
       "3       634.0       338.0       466.0       122.0         0.0     0.0  \n",
       "4       350.0       112.0        32.0       212.0         0.0    15.0  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dividir el DataFrame\n",
    "X = df.drop(columns=['Angulo'])\n",
    "y = df['Angulo']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Entrenar los modelos\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Random Forest: 10.268006134969324\n",
      "MAE XGBoost: 11.038879342011514\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluar los modelos\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'MAE Random Forest: {mae_rf}')\n",
    "print(f'MAE XGBoost: {mae_xgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Random Forest: 12.171950746257773\n",
      "RMSE XGBoost: 12.989393744639706\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = lambda y_true, y_pred_rf: np.sqrt(mean_squared_error(y_true, y_pred_rf))\n",
    "rmse_xgb = lambda y_true, y_pred_xgb: np.sqrt(mean_squared_error(y_true, y_pred_xgb))\n",
    "\n",
    "print(f'RMSE Random Forest: {rmse_rf(y_test, y_pred_rf)}')\n",
    "print(f'RMSE XGBoost: {rmse_xgb(y_test, y_pred_xgb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Random Forest (con PCA): 10.285214723926382\n",
      "MAE XGBoost (con PCA): 11.124560795395286\n"
     ]
    }
   ],
   "source": [
    "# 1. Aplicar PCA\n",
    "pca = PCA(n_components=200)\n",
    "X_pca = pca.fit_transform(df.drop(columns=['Angulo']))\n",
    "\n",
    "# 2. Dividir el DataFrame\n",
    "y = df['Angulo']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Entrenar y evaluar los modelos\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar los modelos\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'MAE Random Forest (con PCA): {mae_rf}')\n",
    "print(f'MAE XGBoost (con PCA): {mae_xgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Random Forest: 12.18398904123995\n",
      "RMSE XGBoost: 13.043534845677199\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = lambda y_true, y_pred_rf: np.sqrt(mean_squared_error(y_true, y_pred_rf))\n",
    "rmse_xgb = lambda y_true, y_pred_xgb: np.sqrt(mean_squared_error(y_true, y_pred_xgb))\n",
    "\n",
    "print(f'RMSE Random Forest: {rmse_rf(y_test, y_pred_rf)}')\n",
    "print(f'RMSE XGBoost: {rmse_xgb(y_test, y_pred_xgb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Reducción de dimensionalidad con PCA\n",
    "pca = PCA(n_components=200)\n",
    "X_pca = pca.fit_transform(df.drop(columns=['Angulo']))\n",
    "\n",
    "# División en conjunto de entrenamiento y prueba\n",
    "y = df['Angulo']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definición del espacio de búsqueda para hiperparámetros\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_child_weight': [1, 2, 3, 4, 5],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# Iniciar el modelo XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Iniciar RandomizedSearchCV\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=100, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    cv=3, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ajustar el modelo con RandomizedSearchCV\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE del modelo XGBoost optimizado: 10.175528546198745\n",
      "RMSE XGBoost: 13.043534845677199\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtener los mejores hiperparámetros\n",
    "best_params = search.best_params_\n",
    "\n",
    "# 2. Entrenar XGBoost con los hiperparámetros óptimos\n",
    "optimized_xgb = xgb.XGBRegressor(**best_params, objective='reg:squarederror')\n",
    "optimized_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = optimized_xgb.predict(X_test)\n",
    "\n",
    "# 3. Evaluar el modelo\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE del modelo XGBoost optimizado: {mae}')\n",
    "print(f'RMSE XGBoost: {rmse_xgb(y_test, y_pred_xgb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
